# -*- coding: utf-8 -*-
"""Project 4 - Credit Card Fraud Prediction

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Uh8K2Gxq-0xjzLPIVy1Jxyg1g_zuiUye

# **üåüImport the Depedencies**
*   pandas - making dataframes
*   matplotlib& seaborn - used to make graphs & plots
*   sklearn - to perform regression / classification
*   metrics - to identify outliers / errors etc.
"""

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import seaborn as sns

"""# **üåüData Collection**

## **‚≠êReading Data**
"""

df = pd.read_csv("/content/card_transdata.csv")
df.head()

"""## **‚≠ê Data Analysis and EDA**"""

df.info()

import seaborn as sns
import matplotlib.pyplot as plt


# Create a 2x2 grid of countplots
fig, axes = plt.subplots(2, 2, figsize=(8, 5))

# Plot 1: repeat_retailer vs. fraud
sns.countplot(data=df, x='repeat_retailer', hue='fraud', ax=axes[0, 0])

# Plot 2: used_chip vs. fraud
sns.countplot(data=df, x='used_chip', hue='fraud', ax=axes[0, 1])

# Plot 3: used_pin_number vs. fraud
sns.countplot(data=df, x='used_pin_number', hue='fraud', ax=axes[1, 0])

# Plot 4: online_order vs. fraud
sns.countplot(data=df, x='online_order', hue='fraud', ax=axes[1, 1])

# Set titles for each plot
axes[0, 0].set_title('Repeat Retailer vs. Fraud')
axes[0, 1].set_title('Used Chip vs. Fraud')
axes[1, 0].set_title('Used Pin Number vs. Fraud')
axes[1, 1].set_title('Online Order vs. Fraud')

# Adjust layout
plt.tight_layout()

# Show the plots
plt.show()

import matplotlib.pyplot as plt


# Filter data by fraud category and values less than 500
fraud_data = df[(df['fraud'] == 1) & (df['distance_from_home'] < 50)]['distance_from_home']
not_fraud_data = df[(df['fraud'] == 0) & (df['distance_from_home'] < 50)]['distance_from_home']

# Create a figure with a specified size
plt.figure(figsize=(6, 4))

# Create a histogram
plt.hist(fraud_data, bins=20, alpha=0.5, color='red', label='Fraud')
plt.hist(not_fraud_data, bins=20, alpha=0.5, color='blue', label='Not Fraud')

plt.xlabel('Distance from Home')
plt.ylabel('Frequency')
plt.title('Histogram of Distance from Home (Values < 50) with Hue - Fraud')
plt.legend()

# Show the histogram
plt.show()

import matplotlib.pyplot as plt


# Filter data by fraud category and values less than 500
fraud_data = df[(df['fraud'] == 1) & (df['distance_from_last_transaction'] < 3)]['distance_from_last_transaction']
not_fraud_data = df[(df['fraud'] == 0) & (df['distance_from_last_transaction'] < 3)]['distance_from_last_transaction']

# Create a figure with a specified size
plt.figure(figsize=(6, 4))

# Create a histogram
plt.hist(fraud_data, bins=20, alpha=0.5, color='red', label='Fraud')
plt.hist(not_fraud_data, bins=20, alpha=0.5, color='blue', label='Not Fraud')

plt.xlabel('distance_from_last_transaction')
plt.ylabel('Frequency')
plt.title('Histogram of distance_from_last_transaction (Values < 3) with Hue - Fraud')
plt.legend()

# Show the histogram
plt.show()

import matplotlib.pyplot as plt

# Filter data by fraud category and values less than 500
fraud_data = df[(df['fraud'] == 1) & (df['ratio_to_median_purchase_price'] < 10)]['ratio_to_median_purchase_price']
not_fraud_data = df[(df['fraud'] == 0) & (df['ratio_to_median_purchase_price'] < 10)]['ratio_to_median_purchase_price']

# Create a figure with a specified size
plt.figure(figsize=(6, 4))

# Create a histogram
plt.hist(fraud_data, bins=20, alpha=0.5, color='red', label='Fraud')
plt.hist(not_fraud_data, bins=20, alpha=0.5, color='blue', label='Not Fraud')

plt.xlabel('ratio_to_median_purchase_price')
plt.ylabel('Frequency')
plt.title('Histogram of ratio_to_median_purchase_price (Values < 10) with Hue - Fraud')
plt.legend()

# Show the histogram
plt.show()

import matplotlib.pyplot as plt


# Filter data to include only values less than 30 for all three columns
filtered_data = df[(df['distance_from_home'] < 100) & (df['distance_from_last_transaction'] < 100) & (df['ratio_to_median_purchase_price'] < 100)]

# Create a 1x3 grid of scatterplots
fig, axes = plt.subplots(1, 3, figsize=(17, 5))

# Scatterplot 1: distance_from_home vs. distance_from_last_transaction
axes[0].scatter(filtered_data['distance_from_home'], filtered_data['distance_from_last_transaction'], c=filtered_data['fraud'], cmap='coolwarm', alpha=0.7, s=5)
axes[0].set_xlabel('Distance from Home')
axes[0].set_ylabel('Distance from Last Transaction')
#axes[0].set_title('Distance from Home vs. Distance from Last Transaction')

# Scatterplot 2: distance_from_home vs. ratio_to_median_purchase_price
axes[1].scatter(filtered_data['distance_from_home'], filtered_data['ratio_to_median_purchase_price'], c=filtered_data['fraud'], cmap='coolwarm', alpha=0.7, s=5)
axes[1].set_xlabel('Distance from Home')
axes[1].set_ylabel('Ratio to Median Purchase Price')
#axes[1].set_title('Distance from Home vs. Ratio to Median Purchase Price')

# Scatterplot 3: distance_from_last_transaction vs. ratio_to_median_purchase_price
axes[2].scatter(filtered_data['distance_from_last_transaction'], filtered_data['ratio_to_median_purchase_price'], c=filtered_data['fraud'], cmap='coolwarm', alpha=0.7, s=5)
axes[2].set_xlabel('Distance from Last Transaction')
axes[2].set_ylabel('Ratio to Median Purchase Price')
#axes[2].set_title('Distance from Last Transaction vs. Ratio to Median Purchase Price')

# Adjust layout
plt.tight_layout()

# Show the scatterplots
plt.show()

"""## **‚≠ê Checking for Multicollinearity**"""

correlation_matrix = df.corr()

# Create a correlation heatmap
plt.figure(figsize=(10, 6))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f", vmin=-1, vmax=1, center=0, linewidths=0.5)

plt.title('Correlation Heatmap of All Columns')
plt.show()

"""As the correlation coefficient isn't more than 0.75 or less than -0.75, we dont need concern over correlation issues."""

import seaborn as sns
import matplotlib.pyplot as plt



# Create a countplot of the "fraud" column
plt.figure(figsize=(4, 4))
ax = sns.countplot(data=df, x="fraud")

plt.title("Countplot of 'fraud' Column")

# Annotate the bars with count values
for p in ax.patches:
    ax.annotate(f'{p.get_height()}', (p.get_x() + p.get_width() / 2., p.get_height()), ha='center', va='center', fontsize=7, color='black', xytext=(0, 5), textcoords='offset points')

plt.show()

"""# **üåü Model Selection & Evaluation**

## **‚≠ê Random Forest Regression**
"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix

# Split the data into train and test sets with a similar target distribution
X = df.drop('fraud', axis=1)  # Features
y = df['fraud']  # Target

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42, stratify=y)

# Train a Random Forest classifier
rf_classifier = RandomForestClassifier(random_state=42)
rf_classifier.fit(X_train, y_train)

# Make predictions on both the training and test sets
y_train_pred = rf_classifier.predict(X_train)
y_test_pred = rf_classifier.predict(X_test)

# Evaluate the model and show classification reports and confusion matrices
def evaluate_model(y_true, y_pred, set_name):
    report = classification_report(y_true, y_pred)
    matrix = confusion_matrix(y_true, y_pred)
    print(f"Classification Report for {set_name}:\n{report}")
    print(f"Confusion Matrix for {set_name}:\n{matrix}\n")

# Evaluate on the training data
evaluate_model(y_train, y_train_pred, "Training Data")

# Evaluate on the test data
evaluate_model(y_test, y_test_pred, "Test Data")

"""## **‚≠ê XGBoost**"""

import pandas as pd
from sklearn.model_selection import train_test_split
import xgboost as xgb
from sklearn.metrics import classification_report, confusion_matrix


# Train an XGBoost classifier
xgb_classifier = xgb.XGBClassifier(random_state=42)
xgb_classifier.fit(X_train, y_train)

# Make predictions on both the training and test sets
y_train_pred = xgb_classifier.predict(X_train)
y_test_pred = xgb_classifier.predict(X_test)

# Evaluate the model and show classification reports and confusion matrices
def evaluate_model(y_true, y_pred, set_name):
    report = classification_report(y_true, y_pred)
    matrix = confusion_matrix(y_true, y_pred)
    print(f"Classification Report for {set_name}:\n{report}")
    print(f"Confusion Matrix for {set_name}:\n{matrix}\n")

# Evaluate on the training data
evaluate_model(y_train, y_train_pred, "Training Data")

# Evaluate on the test data
evaluate_model(y_test, y_test_pred, "Test Data")

"""# **üåü Project Conclusion**

As XGBoost and Random forest give the same and best amount of precision and better score, we can use this model for prediction of Credit Card Fraud Detection
"""

